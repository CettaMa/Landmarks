{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c775ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c9bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the output directory exists\n",
    "data = pd.read_csv(\"output/combined_output.csv\")  # Replace with your dataset\n",
    "\n",
    "# Drop columns if all values in 'EAR', 'MAR', 'Pupil Circularity', or 'MOE' are zero\n",
    "# Check if there are any 0 values in the specified columns\n",
    "numeric_cols = ['EAR', 'MAR', 'Pupil Circularity', 'MOE']\n",
    "for col in numeric_cols:\n",
    "    data[col] = data[col].replace(0, np.nan)\n",
    "data = data.dropna(subset=numeric_cols)\n",
    "X = data.drop([\"State\",\"Time\",\"Video\"], axis=1)  # Replace 'label' with your target column\n",
    "# Encode the target column\n",
    "y = data[\"State\"]  # Replace 'State' with your target column\n",
    "# Scale the features \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c9d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the parameter grid for XGBoost\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [2, 3, 4, 5],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "#     'subsample': [0.7, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# xgb = XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# # GridSearchCV for hyperparameter tuning\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=xgb,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best cross-validation accuracy: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# # Evaluate on test set\n",
    "# best_xgb = grid_search.best_estimator_\n",
    "# y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# print(\"Test Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "# print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred, average=\"weighted\")))\n",
    "# print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred, average=\"weighted\")))\n",
    "# print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred, average=\"weighted\")))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Save the best model\n",
    "# with open(\"xgb_best_model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(best_xgb, f)\n",
    "# print(\"Best XGBoost model saved as xgb_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1650e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameter grids\n",
    "models = {\n",
    "    \"KNN\": (KNeighborsClassifier(), {\"n_neighbors\": [3, 5, 7]}),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42), {\"max_depth\": [2, 4, 6, 8]}),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), {\"n_estimators\": [50, 100], \"max_depth\": [4, 6, 8]}),\n",
    "    \"SVM\": (SVC(probability=True, random_state=42), {\"kernel\": [\"linear\", \"rbf\"], \"C\": [0.1, 1, 10]}),\n",
    "    \"XGBoost\": (XGBClassifier(eval_metric=\"logloss\", random_state=42), {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [2, 3, 4, 5],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "    }),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13bc3180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training KNN...\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Params: {'n_neighbors': 3}\n",
      "Accuracy: 0.9740, F1: 0.9739, Recall: 0.9740, Precision: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       481\n",
      "           1       0.94      0.91      0.92        97\n",
      "\n",
      "    accuracy                           0.97       578\n",
      "   macro avg       0.96      0.95      0.95       578\n",
      "weighted avg       0.97      0.97      0.97       578\n",
      "\n",
      "\n",
      "Training Decision Tree...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params: {'max_depth': 6}\n",
      "Accuracy: 0.9671, F1: 0.9671, Recall: 0.9671, Precision: 0.9670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       481\n",
      "           1       0.91      0.90      0.90        97\n",
      "\n",
      "    accuracy                           0.97       578\n",
      "   macro avg       0.94      0.94      0.94       578\n",
      "weighted avg       0.97      0.97      0.97       578\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Params: {'max_depth': 6, 'n_estimators': 50}\n",
      "Accuracy: 0.9740, F1: 0.9741, Recall: 0.9740, Precision: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       481\n",
      "           1       0.92      0.93      0.92        97\n",
      "\n",
      "    accuracy                           0.97       578\n",
      "   macro avg       0.95      0.96      0.95       578\n",
      "weighted avg       0.97      0.97      0.97       578\n",
      "\n",
      "\n",
      "Training SVM...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Params: {'C': 10, 'kernel': 'linear'}\n",
      "Accuracy: 0.9775, F1: 0.9774, Recall: 0.9775, Precision: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       481\n",
      "           1       0.95      0.92      0.93        97\n",
      "\n",
      "    accuracy                           0.98       578\n",
      "   macro avg       0.97      0.95      0.96       578\n",
      "weighted avg       0.98      0.98      0.98       578\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Accuracy: 0.9723, F1: 0.9723, Recall: 0.9723, Precision: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       481\n",
      "           1       0.92      0.92      0.92        97\n",
      "\n",
      "    accuracy                           0.97       578\n",
      "   macro avg       0.95      0.95      0.95       578\n",
      "weighted avg       0.97      0.97      0.97       578\n",
      "\n",
      "\n",
      "Model comparison saved as model/model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for name, (model, param_grid) in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    grid = GridSearchCV(\n",
    "        model, param_grid, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    # Calculate inference time\n",
    "    start_time = time.time()\n",
    "    _ = best_model.predict(X_test)\n",
    "    total_inference_time = time.time() - start_time\n",
    "    inference_time_per_sample = total_inference_time / len(X_test)\n",
    "\n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    print(\n",
    "        f\"Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}\"\n",
    "    )\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # Save model\n",
    "    with open(f\"model/{name.replace(' ', '_').lower()}_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1 Score\": f1,\n",
    "            \"Recall\": recall,\n",
    "            \"Precision\": precision,\n",
    "            \"Inference Time (s)\": inference_time_per_sample,\n",
    "            \"Best Params\": grid.best_params_,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model/model_comparison.csv\", index=False)\n",
    "print(\"\\nModel comparison saved as model/model_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
